"""
Gerador de Respostas Emp√°ticas Inteligentes para NPS
Usa TessLLM para criar respostas personalizadas baseadas no feedback do cliente
"""

from typing import Optional, Dict, Any, List
import os
import sys
from pathlib import Path

# Adicionar diret√≥rio pai ao path
sys.path.insert(0, str(Path(__file__).parent.parent))

from agents.llm.tess_llm import TessLLM
from langchain_core.prompts import PromptTemplate
from langsmith import traceable


class EmpatheticResponseGenerator:
    """Gera respostas emp√°ticas INTELIGENTES usando Tess AI"""
    
    def __init__(self):
        """Inicializa o gerador com TessLLM"""
        self.llm = TessLLM(temperature=0.7, max_tokens=200)
        
        # Prompt template para respostas emp√°ticas
        self.prompt_template = PromptTemplate(
            input_variables=["score", "categoria", "feedback", "sentimento", "contexto"],
            template="""Voc√™ √© a Tess, assistente emp√°tica da Pareto, especializada em atendimento ao cliente.

CONTEXTO DA AVALIA√á√ÉO:
- Score NPS: {score}/10
- Categoria: {categoria}
- Sentimento detectado: {sentimento}
- Feedback do cliente: "{feedback}"
{contexto}

TAREFA:
Escreva uma resposta NATURAL, EMP√ÅTICA e PERSONALIZADA para o cliente.

DIRETRIZES:
- Seja genu√≠na e humana, n√£o rob√≥tica
- Reconhe√ßa especificamente o que o cliente mencionou
- Use tom conversacional e profissional
- SEM EMOJIS
- Seja breve (m√°ximo 3-4 linhas)
- Se score baixo: mostre empatia e vontade de resolver
- Se score m√©dio: agrade√ßa e pergunte como melhorar
- Se score alto: celebre e agrade√ßa

IMPORTANTE:
- N√ÉO use frases corporativas gen√©ricas
- N√ÉO repita exatamente o que o cliente disse
- Responda como se fosse uma pessoa real conversando
- Sempre se identifique como "Tess" se necess√°rio

Resposta:"""
        )
    
    @traceable(name="Empathetic Response Generation")
    def generate_response(
        self, 
        score: int, 
        feedback_text: str = "",
        conversation_history: List[Dict] = None,
        sentiment: Dict[str, Any] = None,
        cliente_dados: Optional[Dict[str, Any]] = None
    ) -> str:
        """
        Gera resposta emp√°tica INTELIGENTE baseada na nota E no feedback
        
        Args:
            score: Nota NPS (0-10)
            feedback_text: Feedback textual do cliente
            conversation_history: Hist√≥rico de mensagens (opcional)
            sentiment: Resultado da an√°lise de sentimento (opcional)
            cliente_dados: Dados do cliente do HubSpot (opcional)
            
        Returns:
            Mensagem emp√°tica personalizada e contextualizada
        """
        
        # Determinar categoria NPS
        if score <= 6:
            categoria = "DETRATOR"
        elif score <= 8:
            categoria = "NEUTRO"
        else:
            categoria = "PROMOTOR"
        
        # Extrair sentimento
        sentimento_str = "NEUTRO"
        if sentiment:
            sentimento_str = sentiment.get("sentimento", "NEUTRO")
        
        # Preparar contexto do cliente
        contexto_cliente = ""
        nome = ""
        
        if cliente_dados:
            props = cliente_dados.get("properties", {})
            nome = props.get("firstname", "")
            
            if nome:
                contexto_cliente = f"\n- Nome do cliente: {nome}"
        
        # Construir prompt personalizado
        if nome:
            # Vers√£o COM nome
            prompt = f"""Voc√™ √© a Tess, da Pareto.

CONTEXTO:
- Cliente: {nome}
- Score: {score}/10 ({categoria})
- Feedback: "{feedback_text}"

TAREFA:
Responda o {nome} de forma natural.

DIRETRIZES:
- Use o nome {nome}
- SEM EMOJIS (proibido)
- Curto e direto (m√°x 3 linhas)
- N√£o use frases prontas de call center
- Agrade√ßa sinceramente

Resposta:"""
        else:
            # Vers√£o SEM nome
            prompt = f"""Voc√™ √© a Tess, da Pareto.

CONTEXTO:
- Score: {score}/10 ({categoria})
- Feedback: "{feedback_text}"

TAREFA:
Agrade√ßa a avalia√ß√£o de forma natural.

DIRETRIZES:
- SEM EMOJIS (proibido)
- Curto e direto (m√°x 3 linhas)
- N√£o use frases prontas de call center

Resposta:"""
        
        try:
            # Gerar resposta com TessLLM
            response = self.llm.invoke(prompt)
            
            print(f"‚úÖ Resposta emp√°tica gerada via TessLLM (score: {score}, categoria: {categoria})")
            return response.strip()
            
        except Exception as e:
            print(f"‚ùå Erro ao gerar resposta emp√°tica: {e}")
            # Fallback para resposta b√°sica
            return self._fallback_response(score, feedback_text, nome)
    
    def _fallback_response(self, score: int, feedback_text: str, nome: str = "") -> str:
        """
        Resposta inteligente baseada em an√°lise do feedback
        Mais sofisticada que templates fixos
        """
        
        # Analisar se tem feedback textual
        has_feedback = bool(feedback_text and len(feedback_text.strip()) > 3)
        name_part = f", {nome}" if nome else ""
        snippet = feedback_text.strip() if feedback_text else ""
        if len(snippet) > 80:
            snippet = snippet[:77] + "..."
        snippet_text = f' Voc√™ comentou "{snippet}".' if snippet else ""
        
        if score <= 6:  # DETRATOR
            if has_feedback:
                return f"Sinto muito{name_part} pela experi√™ncia.{snippet_text} Pode me contar mais detalhes para eu ajudar?"
            return f"Sinto muito{name_part} pela experi√™ncia. Pode me dizer o que aconteceu? Isso vai nos ajudar a melhorar."
        
        if score <= 8:  # NEUTRO
            if has_feedback:
                return f"Obrigado{name_part} pelo feedback.{snippet_text} O que faltou para ficar excelente?"
            return f"Obrigado{name_part} pela avalia√ß√£o. O que faltou para ser uma experi√™ncia √≥tima?"
        
        # PROMOTOR
        if has_feedback:
            return f"Que bom saber disso{name_part}!{snippet_text} O que voc√™ mais gostou?"
        return f"Que bom saber disso{name_part}. Obrigado pela confian√ßa!"
    
    @staticmethod
    def generate_follow_up_question(score: int) -> str:
        """Gera pergunta de follow-up baseada na nota"""
        
        if score <= 6:
            return "O que aconteceu que te deixou insatisfeito(a)?"
        elif score <= 8:
            return "O que falta para sua experi√™ncia ser perfeita?"
        else:
            return "O que voc√™ mais gostou na nossa parceria?"


if __name__ == "__main__":
    # Testes
    generator = EmpatheticResponseGenerator()
    
    print("üß™ Testando Respostas Inteligentes\n")
    
    test_cases = [
        (3, "O atendimento foi horr√≠vel, ningu√©m me respondeu"),
        (2, "O produto n√£o funciona, cheio de bugs"),
        (5, "Muito caro para o que oferece"),
        (7, "T√° ok, mas poderia ser melhor"),
        (8, "Normal, nada de especial"),
        (10, "Adorei tudo! Voc√™s s√£o incr√≠veis!"),
        (9, "A equipe de suporte √© excelente"),
        (5, ""),  # Sem feedback
    ]
    
    for score, feedback in test_cases:
        print(f"Score: {score}/10")
        print(f"Feedback: '{feedback}'")
        print(f"Resposta: {generator.generate_response(score, feedback)}")
        print("-" * 80)
